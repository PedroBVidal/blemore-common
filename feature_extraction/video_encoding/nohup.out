Traceback (most recent call last):
  File "/home/pbqv20/blemore-common/feature_extraction/video_encoding/EmotionCLIP_features_gpu.py", line 5, in <module>
    from transformers import AutoProcessor, CLIPModel
ModuleNotFoundError: No module named 'transformers'
Using device: cuda
Loading FER-specialized model: jiangchengchengNLP/EmotionCLIP-V2
Traceback (most recent call last):
  File "/home/pbqv20/blemore-common/feature_extraction/video_encoding/EmotionCLIP_features_gpu.py", line 27, in <module>
    processor_clip = AutoProcessor.from_pretrained(model_name)
  File "/home/pbqv20/anaconda3/envs/blemore_comp/lib/python3.10/site-packages/transformers/models/auto/processing_auto.py", line 419, in from_pretrained
    raise ValueError(
ValueError: Unrecognized processing class in jiangchengchengNLP/EmotionCLIP-V2. Can't instantiate a processor, a tokenizer, an image processor, a video processor or a feature extractor for this model. Make sure the repository contains the files of at least one of those processing classes.
Using device: cuda
Loading FER-specialized model: jiangchengchengNLP/EmotionCLIP-V2
Traceback (most recent call last):
  File "/home/pbqv20/blemore-common/feature_extraction/video_encoding/EmotionCLIP_features_gpu.py", line 27, in <module>
    processor_clip = AutoProcessor.from_pretrained(model_name)
  File "/home/pbqv20/anaconda3/envs/blemore_comp/lib/python3.10/site-packages/transformers/models/auto/processing_auto.py", line 419, in from_pretrained
    raise ValueError(
ValueError: Unrecognized processing class in jiangchengchengNLP/EmotionCLIP-V2. Can't instantiate a processor, a tokenizer, an image processor, a video processor or a feature extractor for this model. Make sure the repository contains the files of at least one of those processing classes.
Using device: cuda
Loading FER-specialized model: jiangchengchengNLP/EmotionCLIP-V2
Traceback (most recent call last):
  File "/home/pbqv20/blemore-common/feature_extraction/video_encoding/EmotionCLIP_features_gpu.py", line 27, in <module>
    processor_clip = AutoProcessor.from_pretrained(model_name)
  File "/home/pbqv20/anaconda3/envs/blemore_comp/lib/python3.10/site-packages/transformers/models/auto/processing_auto.py", line 419, in from_pretrained
    raise ValueError(
ValueError: Unrecognized processing class in jiangchengchengNLP/EmotionCLIP-V2. Can't instantiate a processor, a tokenizer, an image processor, a video processor or a feature extractor for this model. Make sure the repository contains the files of at least one of those processing classes.
Using device: cuda
Loading FER-specialized model: jiangchengchengNLP/EmotionCLIP-V2
Traceback (most recent call last):
  File "/home/pbqv20/blemore-common/feature_extraction/video_encoding/EmotionCLIP_features_gpu.py", line 30, in <module>
    model_clip = CLIPModel.from_pretrained(model_name).to(device)
  File "/home/pbqv20/anaconda3/envs/blemore_comp/lib/python3.10/site-packages/transformers/modeling_utils.py", line 3996, in from_pretrained
    checkpoint_files, sharded_metadata = _get_resolved_checkpoint_files(
  File "/home/pbqv20/anaconda3/envs/blemore_comp/lib/python3.10/site-packages/transformers/modeling_utils.py", line 688, in _get_resolved_checkpoint_files
    raise OSError(
OSError: jiangchengchengNLP/EmotionCLIP-V2 does not appear to have a file named pytorch_model.bin or model.safetensors.
Traceback (most recent call last):
  File "/home/pbqv20/blemore-common/feature_extraction/video_encoding/EmotionCLIP_features_gpu.py", line 24, in <module>
    from EmotionCLIP import model as model_clip
  File "/home/pbqv20/blemore-common/feature_extraction/video_encoding/./EmotionCLIP-V2/EmotionCLIP.py", line 113, in <module>
    model.load_state_dict(torch.load(r'./EmotionCLIP-V2.pth',weights_only=True,map_location='cpu'),strict=True)
  File "/home/pbqv20/anaconda3/envs/blemore_comp/lib/python3.10/site-packages/torch/serialization.py", line 1500, in load
    with _open_file_like(f, "rb") as opened_file:
  File "/home/pbqv20/anaconda3/envs/blemore_comp/lib/python3.10/site-packages/torch/serialization.py", line 768, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/pbqv20/anaconda3/envs/blemore_comp/lib/python3.10/site-packages/torch/serialization.py", line 749, in __init__
    super().__init__(open(name, mode))  # noqa: SIM115
FileNotFoundError: [Errno 2] No such file or directory: './EmotionCLIP-V2.pth'
Loading EmotionCLIP-V2 weights...
Traceback (most recent call last):
  File "/home/pbqv20/blemore-common/feature_extraction/video_encoding/EmotionCLIP_features_gpu.py", line 32, in <module>
    from EmotionCLIP import model as model_clip
  File "/home/pbqv20/blemore-common/feature_extraction/video_encoding/EmotionCLIP-V2/EmotionCLIP.py", line 113, in <module>
    model.load_state_dict(torch.load(r'./EmotionCLIP-V2.pth',weights_only=True,map_location='cpu'),strict=True)
  File "/home/pbqv20/anaconda3/envs/blemore_comp/lib/python3.10/site-packages/torch/serialization.py", line 1572, in load
    raise pickle.UnpicklingError(_get_wo_message(str(e))) from None
_pickle.UnpicklingError: Weights only load failed. In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.
Please file an issue with the following so that we can make `weights_only=True` compatible with your use case: WeightsUnpickler error: 

Unsupported operand 118

Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.
Loading EmotionCLIP-V2 weights...
Traceback (most recent call last):
  File "/home/pbqv20/blemore-common/feature_extraction/video_encoding/EmotionCLIP_features_gpu.py", line 32, in <module>
    from EmotionCLIP import model as model_clip
  File "/home/pbqv20/blemore-common/feature_extraction/video_encoding/EmotionCLIP-V2/EmotionCLIP.py", line 113, in <module>
    model.load_state_dict(torch.load(r'./EmotionCLIP-V2.pth',weights_only=False,map_location='cpu'),strict=True)
  File "/home/pbqv20/anaconda3/envs/blemore_comp/lib/python3.10/site-packages/torch/serialization.py", line 1573, in load
    return _legacy_load(
  File "/home/pbqv20/anaconda3/envs/blemore_comp/lib/python3.10/site-packages/torch/serialization.py", line 1822, in _legacy_load
    magic_number = pickle_module.load(f, **pickle_load_args)
_pickle.UnpicklingError: invalid load key, 'v'.
